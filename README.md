# Corner_Detect_Algorithms

## Project Overview
Implementation and Analysis of Various Corner Detection Algorithms 
as a team project of the Visual Perception and Learning course

## Abstract
Our study displays a comparison of various corner
detection algorithms where we used a set of real-world images
and complexities such as noise and scale variation in order to
find out which algorithm is the most efficient for feature
detection and matching. The algorithms that we used were Scale
Invariant Feature Transform (SIFT), Oriented FAST and
Rotated BRIEF (ORB), and KAZE. Each algorithm’s
performance was evaluated using a set of images that featured
different archeological structures such as Mt. Rushmore and
Notre Dame under different conditions. Our analysis made use of
the OpenCV library for the algorithm implementation in order
to understand how each technique affects feature detection and
matching results. We discussed the computational intensity of
each of the algorithms and their applicability to real-world uses
in different scenarios.

Keywords— Computer Vision, SIFT, ORB, KAZE, Feature
Matching, Algorithms

## Team Members
- Hyunhee Kwak: Scale Invariant Feature Transform(SIFT)
- Kenichi Sakamoto: Oriented FAST and Rotated BRIEF (ORB)
- Ziyad Kassar: KAZE


## My Contributions
I conducted a review of the Scale-Invariant Feature Transform (SIFT) 
keypoint detection algorithm and performed feature matching using 
its descriptor. I analyzed the SIFT process by adjusting its parameters 
to assess their impact on accuracy.

You can find my contributions mainly in the following file:
- SIFT.ipynb
- CS659 Project Report.pdf (SIFT)
